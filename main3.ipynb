{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main3: portfolio-ready rebuild\n",
    "Step-by-step refresh toward a cleaner, more reproducible pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n",
      "3.12.3\n"
     ]
    }
   ],
   "source": [
    "import sys, platform\n",
    "print(sys.executable)\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dir exists: True\n",
      "Data_original dir exists: True\n",
      "Train classes: ['biryani', 'chapli_kebab', 'chocolate_cake', 'samosa', 'seekh_kebab']\n",
      "Validation classes: ['biryani', 'chapli_kebab', 'chocolate_cake', 'samosa', 'seekh_kebab']\n",
      "Orig Train classes: ['biryani', 'chapli_kebab', 'chocolate_cake', 'samosa', 'seekh_kebab']\n",
      "Orig Validation classes: ['biryani', 'chapli_kebab', 'chocolate_cake', 'samosa', 'seekh_kebab']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "root = Path('.')\n",
    "data_dir = root / 'Data'\n",
    "data_original_dir = root / 'Data_original'\n",
    "print('Data dir exists:', data_dir.exists())\n",
    "print('Data_original dir exists:', data_original_dir.exists())\n",
    "if data_dir.exists():\n",
    "    train_dir = data_dir / 'Train'\n",
    "    val_dir = data_dir / 'Validation'\n",
    "    print('Train classes:', sorted([p.name for p in train_dir.iterdir() if p.is_dir()]))\n",
    "    print('Validation classes:', sorted([p.name for p in val_dir.iterdir() if p.is_dir()]))\n",
    "if data_original_dir.exists():\n",
    "    train_dir_o = data_original_dir / 'Train'\n",
    "    val_dir_o = data_original_dir / 'Validation'\n",
    "    print('Orig Train classes:', sorted([p.name for p in train_dir_o.iterdir() if p.is_dir()]))\n",
    "    print('Orig Validation classes:', sorted([p.name for p in val_dir_o.iterdir() if p.is_dir()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented train counts: {'biryani': 95, 'chapli_kebab': 95, 'chocolate_cake': 150, 'samosa': 110, 'seekh_kebab': 95}\n",
      "Augmented val counts: {'biryani': 5, 'chapli_kebab': 4, 'chocolate_cake': 7, 'samosa': 5, 'seekh_kebab': 4}\n",
      "Original train counts: {'biryani': 19, 'chapli_kebab': 19, 'chocolate_cake': 30, 'samosa': 22, 'seekh_kebab': 19}\n",
      "Original val counts: {'biryani': 5, 'chapli_kebab': 4, 'chocolate_cake': 7, 'samosa': 5, 'seekh_kebab': 4}\n",
      "Total augmented train: 545\n",
      "Total original train: 109\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "def count_images(root: Path):\n",
    "    counts = {}\n",
    "    if not root.exists():\n",
    "        return counts\n",
    "    for cls in sorted([p for p in root.iterdir() if p.is_dir()]):\n",
    "        counts[cls.name] = len(list(cls.glob('*.jpg')))\n",
    "    return counts\n",
    "\n",
    "train_counts = count_images(Path('Data')/'Train')\n",
    "val_counts = count_images(Path('Data')/'Validation')\n",
    "orig_train_counts = count_images(Path('Data_original')/'Train')\n",
    "orig_val_counts = count_images(Path('Data_original')/'Validation')\n",
    "\n",
    "print('Augmented train counts:', train_counts)\n",
    "print('Augmented val counts:', val_counts)\n",
    "print('Original train counts:', orig_train_counts)\n",
    "print('Original val counts:', orig_val_counts)\n",
    "print('Total augmented train:', sum(train_counts.values()))\n",
    "print('Total original train:', sum(orig_train_counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split counts per class:\n",
      "train {'biryani': 14, 'chapli_kebab': 13, 'chocolate_cake': 23, 'samosa': 17, 'seekh_kebab': 13}\n",
      "val {'biryani': 5, 'chapli_kebab': 5, 'chocolate_cake': 7, 'samosa': 5, 'seekh_kebab': 5}\n",
      "test {'biryani': 5, 'chapli_kebab': 5, 'chocolate_cake': 7, 'samosa': 5, 'seekh_kebab': 5}\n",
      "Totals: {'train': 80, 'val': 27, 'test': 27}\n"
     ]
    }
   ],
   "source": [
    "import random, shutil\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "\n",
    "source_dirs = [Path('Data_original/Train'), Path('Data_original/Validation')]\n",
    "out_root = Path('Data_split')\n",
    "\n",
    "# discover classes from source\n",
    "classes = [p.name for p in sorted(source_dirs[0].iterdir()) if p.is_dir()]\n",
    "\n",
    "# collect images per class across train/val\n",
    "per_class = {}\n",
    "for cls in classes:\n",
    "    imgs = []\n",
    "    for src in source_dirs:\n",
    "        cls_path = src / cls\n",
    "        imgs.extend(sorted(cls_path.glob('*.jpg')))\n",
    "    per_class[cls] = imgs\n",
    "\n",
    "train_ratio, val_ratio, test_ratio = 0.6, 0.2, 0.2\n",
    "\n",
    "# reset output split dirs\n",
    "if out_root.exists():\n",
    "    shutil.rmtree(out_root)\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for cls in classes:\n",
    "        (out_root / split / cls).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "split_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for cls, imgs in per_class.items():\n",
    "    imgs = list(imgs)\n",
    "    random.shuffle(imgs)\n",
    "    n = len(imgs)\n",
    "    test_n = max(1, int(round(n * test_ratio)))\n",
    "    val_n = max(1, int(round(n * val_ratio)))\n",
    "    if test_n + val_n >= n:\n",
    "        test_n = max(1, int(n * 0.2))\n",
    "        val_n = max(1, int(n * 0.2))\n",
    "        if test_n + val_n >= n:\n",
    "            val_n = max(1, n - test_n - 1)\n",
    "    test_imgs = imgs[:test_n]\n",
    "    val_imgs = imgs[test_n : test_n + val_n]\n",
    "    train_imgs = imgs[test_n + val_n :]\n",
    "    for img in train_imgs:\n",
    "        shutil.copy2(img, out_root / 'train' / cls / img.name)\n",
    "        split_counts['train'][cls] += 1\n",
    "    for img in val_imgs:\n",
    "        shutil.copy2(img, out_root / 'val' / cls / img.name)\n",
    "        split_counts['val'][cls] += 1\n",
    "    for img in test_imgs:\n",
    "        shutil.copy2(img, out_root / 'test' / cls / img.name)\n",
    "        split_counts['test'][cls] += 1\n",
    "\n",
    "print('Split counts per class:')\n",
    "for split in ['train', 'val', 'test']:\n",
    "    print(split, {cls: split_counts[split][cls] for cls in classes})\n",
    "print('Totals:', {split: sum(split_counts[split].values()) for split in split_counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "train_dir = Path('Data_split/train')\n",
    "val_dir = Path('Data_split/val')\n",
    "test_dir = Path('Data_split/test')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.1,\n",
    "    fill_mode='nearest',\n",
    ")\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    ")\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    ")\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print('Train samples:', train_gen.samples)\n",
    "print('Val samples:', val_gen.samples, 'shuffle:', val_gen.shuffle)\n",
    "print('Test samples:', test_gen.samples, 'shuffle:', test_gen.shuffle)\n",
    "print('Classes:', train_gen.class_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
